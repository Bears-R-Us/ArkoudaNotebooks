{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using New York City Taxi Data to illistrate using Arkouda with Pandas/NumPy\n",
    "\n",
    "This notebook shows some examples of how to interoperate between Pandas and Arkouda at a small scale to allow it to be run on a 16GB laptop.\n",
    "Remember, Arkouda is not trying to replace Pandas but to allow for some Pandas-style operation at a much larger scale. In our experience Pandas can handle dataframes up to about **500 million rows** before performance becomes a real issue, this is provided that you run on a sufficently capable compute server. Arkouda breaks the shared memory paradigm and scales its operations to dataframes with over **200 billion rows**, maybe even a trillion. In practice we have run Arkouda server operations on columns of one trillion elements running on 512 compute nodes. This yielded a **>20TB dataframe** in Arkouda.\n",
    "\n",
    "- Import Arkouda package and connect to the Arkouda server\n",
    "- import other useful packages\n",
    "- Define some python helper functions for ETL (Extract/Transform/Load)\n",
    "- Define a python function to transfer dataframes from Pandas to Arkouda\n",
    "- Read NYC taxi csv into Pandas\n",
    "- Put dataframe columns into the Arkouda server\n",
    "- Compute taxi ride duration in Pandas and in Arkouda and histogram data\n",
    "- Read NYC Taxi Zone Lookup Table (tzlut) into Pandas\n",
    "- Transfer tzlut to Arkouda\n",
    "- Compute something with Groupby/aggregate in Pandas and in Arkouda\n",
    "  - Groupby on pickup and dropoff location ids\n",
    "  - use groupby/aggregate on edge list to compute different things\n",
    "    - min/max/mean/std distance between location ids\n",
    "    - min/max/mean/std time between location ids\n",
    "    - number of trips between location ids\n",
    "    - other things\n",
    "  - \n",
    "  - other things\n",
    "- model number of taxis at a given time\n",
    "- model taxis as specific entities (Kalman filter?)\n",
    "  - use time and location ids\n",
    "  - probability of paths of taxis\n",
    "  - ...\n",
    "- other things?\n",
    "\n",
    "New York City Taxi Data\n",
    "----------------------------------\n",
    "[Yellow Trips Data Dictionary](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "\n",
    "[NYC Yellow Taxi Trip Records Jan 2020](https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv)\n",
    "\n",
    "[Green Trips Data Dictionary](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf)\n",
    "\n",
    "[NYC Green  Taxi Trip Records Jan 2020](https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2020-01.csv)\n",
    "\n",
    "[NYC Taxi Zone Lookup Table](https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv)\n",
    "\n",
    "[NYC Taxi Zone Shapefile](https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Arkouda package and connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arkouda as ak\n",
    "ak.connect(connect_url=\"tcp://localhost:5555\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion functions for ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion from csv field to int64\n",
    "# try to convert to int, on exception (empty or other string) convert to 0\n",
    "def cvt_to_int64(v):\n",
    "    try:\n",
    "        return np.int64(v)\n",
    "    except:\n",
    "        return np.int64(0)  \n",
    "\n",
    "# conversion from csv field to string\n",
    "# try to convert to int, on exception (empty or other string) convert to 0\n",
    "def cvt_to_string(v):\n",
    "    try:\n",
    "        if v == '':\n",
    "            return 'N/A'\n",
    "        else:\n",
    "            return str(v)\n",
    "    except:\n",
    "        return 'N/A'\n",
    "\n",
    "# conversion from csv field (Y,N,empty) to bool\n",
    "# on Y convert to True, on N or empty convert to False\n",
    "def cvt_YN_to_bool(v):\n",
    "    if v == 'Y':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to transfer dataframe to dictionary of Arkouda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all objects in iterable for instance of str\n",
    "# this is a crutch to get a pandas column of str into Arkouda\n",
    "def is_all_str(a):\n",
    "    ret = True\n",
    "    for v in a:\n",
    "        if isinstance(v, str):\n",
    "            ret = True\n",
    "        else:\n",
    "            ret = False\n",
    "            break\n",
    "    return ret\n",
    "\n",
    "# put data frame columns into arkouda server and return a dict of the pdarrays\n",
    "# convert some columns into data types the server can understand\n",
    "def ak_create_akdict_from_df(df):\n",
    "    akdict = {}\n",
    "    for cname in df.keys():\n",
    "        a = df[cname].values\n",
    "            \n",
    "        # int64, float64, and np.bool should go over fine\n",
    "        if a.dtype in [np.int64, np.float64, np.bool]:\n",
    "            akdict[cname] = ak.array(a)\n",
    "            print(cname, \" : \", a.dtype, \"->\", a.dtype)\n",
    "        # time needs to be converted to int64\n",
    "        elif a.dtype in [\"datetime64[ns]\"]:\n",
    "            akdict[cname] = ak.array(a.astype(np.int64))\n",
    "            print(cname, \" : \", a.dtype, \"->\", akdict[cname].dtype)\n",
    "        # convert to arkouda Strings object if whole column is instance of str\n",
    "        elif is_all_str(a):\n",
    "            # convert to python list of str then ak.array can convert to ak.Strings object\n",
    "            akdict[cname] = ak.array(list(a))\n",
    "            print(cname, \" : \", a.dtype, \"->\", 'ak.Strings')\n",
    "        # something I don't understand how to convert to a server data type\n",
    "        else:\n",
    "            print(\"don't know how to convert \", a.dtype, \" !!!\")\n",
    "    return akdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns minutes as a float \n",
    "def ns_to_min(v):\n",
    "    return (v / (1e9 * 60.0))\n",
    "\n",
    "# returns nanoseconds as an int\n",
    "def min_to_ns(v):\n",
    "    return (int(v * 1_000_000_000 * 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow taxi trip data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in yellow taxi data\n",
    "# per yellow data dictionary convert to data types Arkouda can handle\n",
    "# int64, float64, bool\n",
    "cvt = {'VendorID': cvt_to_int64, 'passenger_count': cvt_to_int64, 'RatecodeID': cvt_to_int64,\n",
    "       'store_and_fwd_flag': cvt_YN_to_bool,\n",
    "       'PULocationID': cvt_to_int64, 'DOLocationID':cvt_to_int64, 'payment_type': cvt_to_int64}\n",
    "# explicitly parse date-time fields\n",
    "parse_dates_lst = ['tpep_pickup_datetime','tpep_dropoff_datetime']\n",
    "# call read_csv to parse data with these options\n",
    "ydf = pd.read_csv(\"../Downloads/yellow_tripdata_2020-01.csv\",\n",
    "                  converters=cvt, header=0, low_memory=False,\n",
    "                  parse_dates=parse_dates_lst, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out dataframe\n",
    "ydf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which columns did we read in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which keys we read in from first line of csv data file\n",
    "#print(ydf.keys())\n",
    "print(ydf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataframe to a dictionary of Arkouda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data frame columns into arkouda server\n",
    "# convert some columns into data types the server can understand\n",
    "akdict = ak_create_akdict_from_df(ydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show which columns got transfered to the Arkouda server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which keys made it over to the server\n",
    "print(akdict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the symbol table of the Arkouda server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the arkouda server symbol table\n",
    "print(ak.info(ak.AllSymbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a simple computation in the Arkouda server about pickup-time indexed logically by the store-and-forward flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many records made it to the server?\n",
    "numTotal = akdict['tpep_pickup_datetime'].size\n",
    "\n",
    "# use the store_and_forward column to index tpep_pickup_datetime\n",
    "# see how many times was false\n",
    "numFalse = akdict['tpep_pickup_datetime'][~akdict['store_and_fwd_flag']].size\n",
    "\n",
    "# use the store_and_forward column to index tpep_pickup_datetime\n",
    "# see how many times was true\n",
    "numTrue = akdict['tpep_pickup_datetime'][akdict['store_and_fwd_flag']].size\n",
    "\n",
    "numTotal == numFalse+numTrue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ride duration in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas ride duration \n",
    "ride_duration = ydf['tpep_dropoff_datetime'] - ydf['tpep_pickup_datetime']\n",
    "# pull out ride duration in minutes\n",
    "ride_duration = ride_duration.dt.total_seconds() / 60 # in minutes\n",
    "\n",
    "print(\"min = \", ride_duration.min(),\"max = \", ride_duration.max())\n",
    "print(\"mean = \",ride_duration.mean(),\"stdev = \",ride_duration.std())\n",
    "\n",
    "# how long was the min/max ride to the next integer minute\n",
    "min_ride = math.floor(ride_duration.min())\n",
    "print(\"min_ride = \", min_ride)\n",
    "max_ride = math.ceil(ride_duration.max())\n",
    "print(\"max_ride = \", max_ride)\n",
    "\n",
    "# histogram the ride time bin by the minute\n",
    "nBins = max_ride - min_ride\n",
    "cnts,binEdges = np.histogram(ride_duration, bins=nBins)\n",
    "\n",
    "print(cnts.size,    \"cnts      = \", cnts)\n",
    "print(binEdges.size,\"bin edges = \", binEdges)\n",
    "\n",
    "# plot the histogram the ride time, bin by the minute\n",
    "plt.plot(binEdges[:-1],cnts)\n",
    "plt.yscale('log')\n",
    "plt.xscale('linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ride duration in Arkouda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take delta for ride duration\n",
    "ride_duration = akdict['tpep_dropoff_datetime'] - akdict['tpep_pickup_datetime']\n",
    "# pull out ride duration in minutes\n",
    "ride_duration = ns_to_min(ride_duration)\n",
    "\n",
    "print(\"min = \", ride_duration.min(),\"max = \", ride_duration.max())\n",
    "print(\"mean = \",ride_duration.mean(),\"stdev = \",ride_duration.std())\n",
    "\n",
    "# how long was the min/max ride to the next integer minute\n",
    "min_ride = math.floor(ride_duration.min())\n",
    "print(\"min_ride = \", min_ride)\n",
    "max_ride = math.ceil(ride_duration.max())\n",
    "print(\"max_ride = \", max_ride)\n",
    "\n",
    "# histogram the ride time bin by the minute\n",
    "nBins = max_ride - min_ride\n",
    "cnts = ak.histogram(ride_duration, bins=nBins)\n",
    "\n",
    "# create bin edges because ak.histogram doesn't \n",
    "binEdges = np.linspace(ride_duration.min(), ride_duration.max(), nBins+1)\n",
    "print(binEdges)\n",
    "\n",
    "print(cnts.size,    \"cnts      = \", cnts)\n",
    "print(binEdges.size,\"bin edges = \", binEdges)\n",
    "\n",
    "# plot the histogram the ride time, bin by the minute\n",
    "plt.plot(binEdges[:-1],cnts.to_ndarray())\n",
    "plt.yscale('log')\n",
    "plt.xscale('linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute somehting with trip distance in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ydf['trip_distance'].min(), ydf['trip_distance'].max())\n",
    "print(ydf['trip_distance'].mean(), ydf['trip_distance'].std())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(ydf['trip_distance'],bins=2000)\n",
    "#ax = plt.gca()\n",
    "#ax.set_xlim((ydf['trip_distance'].min(),ydf['trip_distance'].max()))\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute somehting with trip distance in Arkouda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi Zone Lookup Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the taxi-zone-lookup-table\n",
    "cvt = {'Borough':cvt_to_string, 'Zone':cvt_to_string, 'service_zone':cvt_to_string}\n",
    "tzlut = pd.read_csv(\"../Downloads/taxi+_zone_lookup.csv\",converters=cvt)\n",
    "# print out the tzlut which was read from file\n",
    "print(tzlut)\n",
    "\n",
    "# location id is 1-based, index is 0-based\n",
    "# fix it up to be aligned with index in data frame\n",
    "# which means add row zero\n",
    "top_row = pd.DataFrame({'LocationID': [0], 'Borough': ['N/A'], 'Zone': ['N/A'], 'service_zone': ['N/A']})\n",
    "tzlut = pd.concat([top_row, tzlut]).reset_index(drop = True)\n",
    "# print fixed up tzlut\n",
    "tzlut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the columns for all strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns for all strings\n",
    "print([\"{} is all str -> {}\".format(name, is_all_str(tzlut[name].values)) for name in tzlut.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataframe to dictionary of Arkouda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data frame with strings and int64 data\n",
    "aktzlut = ak_create_akdict_from_df(tzlut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what did we get on the server side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aktzlut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy pickup and dropoff location id\n",
    "- Compute something with Groupby/aggregate in Pandas and in Arkouda\n",
    "  - Groupby on pickup and dropoff location ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby puckup(PU) and dropoff(DO) location ids(LID)\n",
    "byLIDs = ak.GroupBy((akdict['PULocationID'], akdict['DOLocationID']))\n",
    "# print unique keys\n",
    "print('unique_keys (PU,DO): ', byLIDs.unique_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use groupby/aggregate on edge list to construct a condensed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a condensed graph of LID (PU,DO) pairs with different weights\n",
    "graphLID = {}\n",
    " # vertex names (integer)\n",
    "graphLID['V']    = aktzlut['LocationID']\n",
    "# unique edges\n",
    "graphLID['E']    = byLIDs.unique_keys\n",
    "# edge weight: count of each unique edge\n",
    "graphLID['W_CT'] = byLIDs.count()[1]\n",
    "# edge weight: mean trip distance per edge\n",
    "graphLID['W_TD'] = byLIDs.mean(akdict['trip_distance'])[1]\n",
    "# edge weight: mean ride duration per edge\n",
    "graphLID['W_RD'] = byLIDs.mean(ride_duration)[1]\n",
    "# edge weight: mean fare amount per edge\n",
    "graphLID['W_FA'] = byLIDs.mean(akdict['fare_amount'])[1]\n",
    "# print the graph\n",
    "print(\"graphLID = \", graphLID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute something with the condensed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute something with the condensed graph...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use join-on-eq-with-dt to look at adjacent trips\n",
    "This is one of the most complex operations available in Arkouda and it's not well documented ;-)\n",
    "\n",
    "- `ak.join_on_eq_with_dt(a1, a2, t1, t1, dt, pred, result_limit=1000)`\n",
    "- this function finds places where the first two integer arrays are equal value then uses the predicate to test the second two arrays, if all is true then append indices to result list\n",
    "- so, `if ((a1[i] == a2[j]) and predicate(t1[i],t2[j])) then add (i,j) to the result list`\n",
    "- the `pred` can be `'true_dt'`, `'pos_dt'`, `'abs_dt'`\n",
    "  - `'true_dt'` evaluates to `True` always\n",
    "  - `'pos_dt'` evaluates `((t1     <= t2) && (t2 <= (t1+dt)))`\n",
    "  - `'abs_dt'` evaluates `((t1-dt) <= t2) && (t2 <= (t1+dt)))`\n",
    "- the `result_limit` makes sure you can handle the memory footprint of the result, this isn't implemented well right now in the multi-locale context\n",
    "\n",
    "\n",
    "you can think of this as emitting 2-long chains from the line-graph of edges(trips) where the predicate is true\n",
    "\n",
    "so trip1.DOLocationID is the same as trip2.PULocationID\n",
    "and the second trip happens within time related to the first trip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ak.join_on_eq_with_dt(a1, a2, t1, t1, dt, pred, result_limit=1000)\n",
    "#\n",
    "# you can think of this as emitting 2-long chains from the line-graph of trips where the predicate is true\n",
    "# so trip1.DOLocationID is the same as trip2.PULocationID\n",
    "# and the second trip happens within time related to the first trip\n",
    "#\n",
    "(I,J) = ak.join_on_eq_with_dt(akdict['DOLocationID'], akdict['PULocationID'],\n",
    "                              akdict['tpep_dropoff_datetime'], akdict['tpep_pickup_datetime'],\n",
    "                              min_to_ns(1), 'pos_dt', result_limit=100_000)\n",
    "print(I.size,I,J.size,J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - use join-with-dt\n",
    "  - other things\n",
    "- model number of taxis at a given time\n",
    "- model taxis as specific entities (Kalman filter?)\n",
    "  - use time and location ids\n",
    "  - probability of paths of taxis\n",
    "  - ...\n",
    "- other things?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(I.any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disconnect from the server or shutdown the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disconnect or shutdown the server\n",
    "#ak.disconnect()\n",
    "#ak.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
