{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using New York City Taxi Data to illistrate using Arkouda with Pandas/NumPy\n",
    "\n",
    "This notebook shows some examples of how to interoperate between Pandas and Arkouda at a small scale to allow it to be run on a 16GB laptop.\n",
    "Remember, Arkouda is not trying to replace Pandas but to allow for some Pandas-style operation at a much larger scale. In our experience Pandas can handle dataframes up to about **500 million rows** before performance becomes a real issue, this is provided that you run on a sufficently capable compute server. Arkouda breaks the shared memory paradigm and scales its operations to dataframes with over **200 billion rows**, maybe even a trillion. In practice we have run Arkouda server operations on columns of one trillion elements running on 512 compute nodes. This yielded a **>20TB dataframe** in Arkouda.\n",
    "\n",
    "- Import Arkouda package and connect to the Arkouda server\n",
    "- import other useful packages\n",
    "- Define some python helper functions for ETL (Extract/Transform/Load)\n",
    "- Define a python function to transfer dataframes from Pandas to Arkouda\n",
    "- Read NYC taxi csv into Pandas\n",
    "- Put dataframe columns into the Arkouda server\n",
    "- Compute taxi ride duration in Pandas, compute histogram\n",
    "- Compute taxi ride duration in Arkouda, compute histogram, currently dosen't match exactly to Pandas due to some misunderstanding about Pandas timestamp processing\n",
    "- Compute something with trip distance in Pandas\n",
    "- Compute the same computation in Arkouda\n",
    "- Read NYC Taxi Zone Lookup Table (tzlut) into Pandas\n",
    "- Transfer tzlut to Arkouda\n",
    "- Compute something with Groupby/aggregate in Pandas\n",
    "- Compute something with Groupby/aggregate in Arkouda\n",
    "\n",
    "\n",
    "New York City Taxi Data\n",
    "----------------------------------\n",
    "[Yellow Trips Data Dictionary](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "\n",
    "[NYC Yellow Taxi Trip Records Jan 2020](https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv)\n",
    "\n",
    "[Green Trips Data Dictionary](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf)\n",
    "\n",
    "[NYC Green  Taxi Trip Records Jan 2020](https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2020-01.csv)\n",
    "\n",
    "[NYC Taxi Zone Lookup Table](https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv)\n",
    "\n",
    "[NYC Taxi Zone Shapefile](https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arkouda as ak\n",
    "ak.connect(connect_url=\"tcp://localhost:5555\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion from csv field to int64\n",
    "# try to convert to int, on exception (empty or other string) convert to 0\n",
    "def cvt_to_int64(v):\n",
    "    try:\n",
    "        return np.int64(v)\n",
    "    except:\n",
    "        return np.int64(0)  \n",
    "\n",
    "# conversion from csv field to string\n",
    "# try to convert to int, on exception (empty or other string) convert to 0\n",
    "def cvt_to_string(v):\n",
    "    try:\n",
    "        if v == '':\n",
    "            return 'N/A'\n",
    "        else:\n",
    "            return str(v)\n",
    "    except:\n",
    "        return 'N/A'\n",
    "\n",
    "# conversion from csv field (Y,N,empty) to bool\n",
    "# on Y convert to True, on N or empty convert to False\n",
    "def cvt_YN_to_bool(v):\n",
    "    if v == 'Y':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all objects in iterable for instance of str\n",
    "# this is a crutch to get a pandas column of str into Arkouda\n",
    "def is_all_str(a):\n",
    "    ret = True\n",
    "    for v in a:\n",
    "        if isinstance(v, str):\n",
    "            ret = True\n",
    "        else:\n",
    "            ret = False\n",
    "            break\n",
    "    return ret\n",
    "\n",
    "# put data frame columns into arkouda server and return a dict of the pdarrays\n",
    "# convert some columns into data types the server can understand\n",
    "def ak_create_akdict_from_df(df):\n",
    "    akdict = {}\n",
    "    for cname in df.keys():\n",
    "        a = df[cname].values\n",
    "            \n",
    "        # int64, float64, and np.bool should go over fine\n",
    "        if a.dtype in [np.int64, np.float64, np.bool]:\n",
    "            akdict[cname] = ak.array(a)\n",
    "            print(cname, \" : \", a.dtype, \"->\", a.dtype)\n",
    "        # time needs to be converted to int64\n",
    "        elif a.dtype in [\"datetime64[ns]\"]:\n",
    "            akdict[cname] = ak.array(a.astype(np.int64))\n",
    "            print(cname, \" : \", a.dtype, \"->\", akdict[cname].dtype)\n",
    "        # convert to arkouda Strings object if whole column is instance of str\n",
    "        elif is_all_str(a):\n",
    "            # convert to python list of str then ak.array can convert to ak.Strings object\n",
    "            akdict[cname] = ak.array(list(a))\n",
    "            print(cname, \" : \", a.dtype, \"->\", 'ak.Strings')\n",
    "        # something I don't understand how to convert to a server data type\n",
    "        else:\n",
    "            print(\"don't know how to convert \", a.dtype, \" !!!\")\n",
    "    return akdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow taxi trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in yellow taxi data\n",
    "# per yellow data dictionary convert to data types Arkouda can handle\n",
    "# int64, float64, bool\n",
    "cvt = {'VendorID': cvt_to_int64, 'passenger_count': cvt_to_int64, 'RatecodeID': cvt_to_int64,\n",
    "       'store_and_fwd_flag': cvt_YN_to_bool,\n",
    "       'PULocationID': cvt_to_int64, 'DOLocationID':cvt_to_int64, 'payment_type': cvt_to_int64}\n",
    "# explicitly parse date-time fields\n",
    "parse_dates_lst = ['tpep_pickup_datetime','tpep_dropoff_datetime']\n",
    "# call read_csv to parse data with these options\n",
    "ydf = pd.read_csv(\"../Downloads/yellow_tripdata_2020-01.csv\",\n",
    "                  converters=cvt, header=0, low_memory=False,\n",
    "                  parse_dates=parse_dates_lst, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out dataframe\n",
    "ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which keys we read in from first line of csv data file\n",
    "#print(ydf.keys())\n",
    "print(ydf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data frame columns into arkouda server\n",
    "# convert some columns into data types the server can understand\n",
    "akdict = ak_create_akdict_from_df(ydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which keys made it over to the server\n",
    "print(akdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gc.garbage)\n",
    "gc.collect()\n",
    "# print out the arkouda server symbol table\n",
    "print(ak.info(ak.AllSymbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many records made it to the server?\n",
    "numTotal = akdict['tpep_pickup_datetime'].size\n",
    "\n",
    "# use the store_and_forward column to index tpep_pickup_datetime\n",
    "# see how many time was false\n",
    "numFalse = akdict['tpep_pickup_datetime'][~akdict['store_and_fwd_flag']].size\n",
    "\n",
    "# use the store_and_forward column to index tpep_pickup_datetime\n",
    "# see how many time was true\n",
    "numTrue = akdict['tpep_pickup_datetime'][akdict['store_and_fwd_flag']].size\n",
    "\n",
    "numTotal == numFalse+numTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.int64(pd.NaT))\n",
    "print(pd.Timestamp.today())\n",
    "print(np.int64(pd.Timestamp.today().to_datetime64()))\n",
    "print(ydf['tpep_dropoff_datetime'].min(),ydf['tpep_dropoff_datetime'].argmin(),\n",
    "      ydf['tpep_pickup_datetime'].min(),ydf['tpep_pickup_datetime'].argmin())\n",
    "print(ydf['tpep_dropoff_datetime'].max(),ydf['tpep_dropoff_datetime'].argmax(),\n",
    "      ydf['tpep_pickup_datetime'].max(),ydf['tpep_pickup_datetime'].argmax())\n",
    "print(akdict['tpep_dropoff_datetime'].min(),akdict['tpep_dropoff_datetime'].argmin(),\n",
    "      akdict['tpep_pickup_datetime'].min(),akdict['tpep_pickup_datetime'].argmin())\n",
    "print(akdict['tpep_dropoff_datetime'].max(), akdict['tpep_dropoff_datetime'].argmax(),\n",
    "      akdict['tpep_pickup_datetime'].max(), akdict['tpep_pickup_datetime'].argmax())\n",
    "#print(akdict['tpep_dropoff_datetime'].mink(10))\n",
    "print(akdict['tpep_dropoff_datetime'].argmink(20))\n",
    "#print(akdict['tpep_pickup_datetime'].mink(10))\n",
    "print(akdict['tpep_pickup_datetime'].argmink(20))\n",
    "print(akdict['tpep_dropoff_datetime'].maxk(28))\n",
    "print(akdict['tpep_dropoff_datetime'].argmaxk(28))\n",
    "print(akdict['tpep_pickup_datetime'].maxk(28))\n",
    "print(akdict['tpep_pickup_datetime'].argmaxk(28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_duration = ydf['tpep_dropoff_datetime'] - ydf['tpep_pickup_datetime']\n",
    "# pull out ride duration in minutes\n",
    "ride_duration = ride_duration.dt.seconds / 60 # in minutes\n",
    "print(\"min = \", ride_duration.min(),\"max = \", ride_duration.max())\n",
    "print(\"mean = \",ride_duration.mean(),\"stdev = \",ride_duration.std(),\"median =\",ride_duration.median())\n",
    "# how long was the maximum ride to the next integer minute\n",
    "max_ride = math.ceil(ride_duration.max())\n",
    "print(\"max_ride = \", max_ride)\n",
    "\n",
    "# histogram the ride time bin by the minute\n",
    "nBins = max_ride\n",
    "cnts,bin_edges = np.histogram(ride_duration, bins=nBins)\n",
    "print(cnts.size,     \"cnts      = \", cnts)\n",
    "print(bin_edges.size,\"bin edges = \", bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ak_time_diff(t0,t1,low,high):\n",
    "    t_low = np.int64(pd.Timestamp(low).to_datetime64())\n",
    "    t_high = np.int64(pd.Timestamp(high).to_datetime64())\n",
    "    return ak.where(((t0 <= t_high) & (t0 >= t_low)\n",
    "                     & (t1 <= t_high) & (t1 >= t_low)\n",
    "                     & (t1 >= t0)), t1 - t0, 0.0)\n",
    "\n",
    "def ns_to_min(v):\n",
    "    return (v / (1e9 * 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take delta for ride duration\n",
    "ride_duration = ak_time_diff(akdict['tpep_pickup_datetime'],akdict['tpep_dropoff_datetime'],\n",
    "                            '2020-01-01', '2020-02-01')\n",
    "# pull out ride duration in minutes\n",
    "ride_duration = ns_to_min(ride_duration)\n",
    "\n",
    "print(\"min = \", ride_duration.min(),\"max = \", ride_duration.max())\n",
    "print(\"mean = \",ride_duration.mean(),\"stdev = \",ride_duration.std())\n",
    "\n",
    "# how long was the maximum ride to the next integer minute\n",
    "max_ride = math.ceil(ride_duration.max())\n",
    "print(\"max_ride = \", max_ride)\n",
    "\n",
    "# histogram the ride time bin by the minute\n",
    "nBins = max_ride\n",
    "cnts = ak.histogram(ride_duration, bins=nBins)\n",
    "print(cnts.size, \"cnts = \", cnts)\n",
    "\n",
    "# create bin edges\n",
    "binEdges = np.linspace(0.0, max_ride, nBins+1)\n",
    "print(binEdges)\n",
    "\n",
    "# plot the histogram the ride time, bin by the minute\n",
    "plt.plot(binEdges[:-1],cnts.to_ndarray())\n",
    "plt.yscale('log')\n",
    "plt.xscale('linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ydf['trip_distance'].min(), ydf['trip_distance'].max())\n",
    "print(ydf['trip_distance'].mean(), ydf['trip_distance'].std(), ydf['trip_distance'].median())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(ydf['trip_distance'],bins=2000)\n",
    "#ax = plt.gca()\n",
    "#ax.set_xlim((ydf['trip_distance'].min(),ydf['trip_distance'].max()))\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi Zone Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the taxi-zone-lookup-table\n",
    "cvt = {'Borough':cvt_to_string, 'Zone':cvt_to_string, 'service_zone':cvt_to_string}\n",
    "tzlut = pd.read_csv(\"../Downloads/taxi+_zone_lookup.csv\",converters=cvt)\n",
    "# print out the tzlut which was read from file\n",
    "tzlut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location id is 1-based, index is 0-based\n",
    "# fix it up to be aligned with index in data frame\n",
    "# which means add row zero\n",
    "top_row = pd.DataFrame({'LocationID': [0], 'Borough': ['N/A'], 'Zone': ['N/A'], 'service_zone': ['N/A']})\n",
    "tzlut = pd.concat([top_row, tzlut]).reset_index(drop = True)\n",
    "# print fixed up tzlut\n",
    "tzlut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns for all strings\n",
    "print([\"{} is all str -> {}\".format(name, is_all_str(tzlut[name].values)) for name in tzlut.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data frame with strings and int64 data\n",
    "aktzlut = ak_create_akdict_from_df(tzlut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aktzlut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disconnect or shutdown the server\n",
    "#ak.disconnect()\n",
    "#ak.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
