{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using New York City Taxi Data to illistrate using Arkouda with Pandas/NumPy\n",
    "\n",
    "This notebook shows some examples of how to interoperate between Pandas and Arkouda at a small scale to allow it to be run on a 16GB laptop.\n",
    "Remember, Arkouda is not trying to replace Pandas but to allow for some Pandas-style operation at a much larger scale. In our experience Pandas can handle dataframes up to about **500 million rows** before performance becomes a real issue, this is provided that you run on a sufficently capable compute server. Arkouda breaks the shared memory paradigm and scales its operations to dataframes with over **200 billion rows**, maybe even a trillion. In practice we have run Arkouda server operations on columns of one trillion elements running on 512 compute nodes. This yielded a **>20TB dataframe** in Arkouda.\n",
    "\n",
    "- Import Arkouda package and connect to the Arkouda server\n",
    "- import other useful packages\n",
    "- Define some python helper functions for ETL (Extract/Transform/Load)\n",
    "- Define a python function to transfer dataframes from Pandas to Arkouda\n",
    "- Read NYC taxi csv into Pandas\n",
    "- Put dataframe columns into the Arkouda server\n",
    "- Compute taxi ride duration in Pandas and in Arkouda and histogram data\n",
    "- Read NYC Taxi Zone Lookup Table (tzlut) into Pandas\n",
    "- Transfer tzlut to Arkouda\n",
    "- Compute something with Groupby/aggregate in Pandas and in Arkouda\n",
    "  - Groupby on pickup and dropoff location ids\n",
    "  - use groupby/aggregate on edge list to compute different things\n",
    "    - min/max/mean/std distance between location ids\n",
    "    - min/max/mean/std time between location ids\n",
    "    - number of trips between location ids\n",
    "    - other things\n",
    "  - \n",
    "  - other things\n",
    "- model number of taxis at a given time\n",
    "- model taxis as specific entities (Kalman filter?)\n",
    "  - use time and location ids\n",
    "  - probability of paths of taxis\n",
    "  - ...\n",
    "- other things?\n",
    "\n",
    "New York City Taxi Data\n",
    "----------------------------------\n",
    "[Yellow Trips Data Dictionary](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)\n",
    "\n",
    "[NYC Yellow Taxi Trip Records Jan 2020](https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv)\n",
    "\n",
    "[Green Trips Data Dictionary](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf)\n",
    "\n",
    "[NYC Green  Taxi Trip Records Jan 2020](https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2020-01.csv)\n",
    "\n",
    "[NYC Taxi Zone Lookup Table](https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv)\n",
    "\n",
    "[NYC Taxi Zone Shapefile](https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Arkouda package and connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arkouda as ak\n",
    "ak.connect(connect_url=\"tcp://localhost:5555\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion functions for ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion from csv field to int64\n",
    "# try to convert to int, on exception (empty or other string) convert to 0\n",
    "def cvt_to_int64(v):\n",
    "    try:\n",
    "        return np.int64(v)\n",
    "    except:\n",
    "        return np.int64(0)  \n",
    "\n",
    "# conversion from csv field to string\n",
    "# try to convert to int, on exception (empty or other string) convert to 0\n",
    "def cvt_to_string(v):\n",
    "    try:\n",
    "        if v == '':\n",
    "            return 'N/A'\n",
    "        else:\n",
    "            return str(v)\n",
    "    except:\n",
    "        return 'N/A'\n",
    "\n",
    "# conversion from csv field (Y,N,empty) to bool\n",
    "# on Y convert to True, on N or empty convert to False\n",
    "def cvt_YN_to_bool(v):\n",
    "    if v == 'Y':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to transfer dataframe to dictionary of Arkouda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all objects in iterable for instance of str\n",
    "# this is a crutch to get a pandas column of str into Arkouda\n",
    "def is_all_str(a):\n",
    "    ret = True\n",
    "    for v in a:\n",
    "        if isinstance(v, str):\n",
    "            ret = True\n",
    "        else:\n",
    "            ret = False\n",
    "            break\n",
    "    return ret\n",
    "\n",
    "# put data frame columns into arkouda server and return a dict of the pdarrays\n",
    "# convert some columns into data types the server can understand\n",
    "def ak_create_akdict_from_df(df):\n",
    "    akdict = {}\n",
    "    for cname in df.keys():\n",
    "        a = df[cname].values\n",
    "            \n",
    "        # int64, float64, and np.bool should go over fine\n",
    "        if a.dtype in [np.int64, np.float64, np.bool]:\n",
    "            akdict[cname] = ak.array(a)\n",
    "            print(cname, \" : \", a.dtype, \"->\", a.dtype)\n",
    "        # time needs to be converted to int64\n",
    "        elif a.dtype in [\"datetime64[ns]\"]:\n",
    "            akdict[cname] = ak.array(a.astype(np.int64))\n",
    "            print(cname, \" : \", a.dtype, \"->\", akdict[cname].dtype)\n",
    "        # convert to arkouda Strings object if whole column is instance of str\n",
    "        elif is_all_str(a):\n",
    "            # convert to python list of str then ak.array can convert to ak.Strings object\n",
    "            akdict[cname] = ak.array(list(a))\n",
    "            print(cname, \" : \", a.dtype, \"->\", 'ak.Strings')\n",
    "        # something I don't understand how to convert to a server data type\n",
    "        else:\n",
    "            print(\"don't know how to convert \", a.dtype, \" !!!\")\n",
    "    return akdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ns_to_min(v):\n",
    "    return (v / (1e9 * 60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow taxi trip data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in yellow taxi data\n",
    "# per yellow data dictionary convert to data types Arkouda can handle\n",
    "# int64, float64, bool\n",
    "cvt = {'VendorID': cvt_to_int64, 'passenger_count': cvt_to_int64, 'RatecodeID': cvt_to_int64,\n",
    "       'store_and_fwd_flag': cvt_YN_to_bool,\n",
    "       'PULocationID': cvt_to_int64, 'DOLocationID':cvt_to_int64, 'payment_type': cvt_to_int64}\n",
    "# explicitly parse date-time fields\n",
    "parse_dates_lst = ['tpep_pickup_datetime','tpep_dropoff_datetime']\n",
    "# call read_csv to parse data with these options\n",
    "ydf = pd.read_csv(\"../Downloads/yellow_tripdata_2020-01.csv\",\n",
    "                  converters=cvt, header=0, low_memory=False,\n",
    "                  parse_dates=parse_dates_lst, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out dataframe\n",
    "ydf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which columns did we read in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which keys we read in from first line of csv data file\n",
    "#print(ydf.keys())\n",
    "print(ydf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataframe to a dictionary of Arkouda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data frame columns into arkouda server\n",
    "# convert some columns into data types the server can understand\n",
    "akdict = ak_create_akdict_from_df(ydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show which columns got transfered to the Arkouda server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which keys made it over to the server\n",
    "print(akdict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the symbol table of the Arkouda server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the arkouda server symbol table\n",
    "print(ak.info(ak.AllSymbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a simple computation in the Arkouda server about pickup-time indexed logically by the store-and-forward flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many records made it to the server?\n",
    "numTotal = akdict['tpep_pickup_datetime'].size\n",
    "\n",
    "# use the store_and_forward column to index tpep_pickup_datetime\n",
    "# see how many time was false\n",
    "numFalse = akdict['tpep_pickup_datetime'][~akdict['store_and_fwd_flag']].size\n",
    "\n",
    "# use the store_and_forward column to index tpep_pickup_datetime\n",
    "# see how many time was true\n",
    "numTrue = akdict['tpep_pickup_datetime'][akdict['store_and_fwd_flag']].size\n",
    "\n",
    "numTotal == numFalse+numTrue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ride duration in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas ride duration \n",
    "ride_duration = ydf['tpep_dropoff_datetime'] - ydf['tpep_pickup_datetime']\n",
    "# pull out ride duration in minutes\n",
    "ride_duration = ride_duration.dt.total_seconds() / 60 # in minutes\n",
    "\n",
    "print(\"min = \", ride_duration.min(),\"max = \", ride_duration.max())\n",
    "print(\"mean = \",ride_duration.mean(),\"stdev = \",ride_duration.std())\n",
    "\n",
    "# how long was the min/max ride to the next integer minute\n",
    "min_ride = math.floor(ride_duration.min())\n",
    "print(\"min_ride = \", min_ride)\n",
    "max_ride = math.ceil(ride_duration.max())\n",
    "print(\"max_ride = \", max_ride)\n",
    "\n",
    "# histogram the ride time bin by the minute\n",
    "nBins = max_ride - min_ride\n",
    "cnts,binEdges = np.histogram(ride_duration, bins=nBins)\n",
    "\n",
    "print(cnts.size,    \"cnts      = \", cnts)\n",
    "print(binEdges.size,\"bin edges = \", binEdges)\n",
    "\n",
    "# plot the histogram the ride time, bin by the minute\n",
    "plt.plot(binEdges[:-1],cnts)\n",
    "plt.yscale('log')\n",
    "plt.xscale('linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ride duration in Arkouda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take delta for ride duration\n",
    "ride_duration = akdict['tpep_dropoff_datetime'] - akdict['tpep_pickup_datetime']\n",
    "# pull out ride duration in minutes\n",
    "ride_duration = ns_to_min(ride_duration)\n",
    "\n",
    "print(\"min = \", ride_duration.min(),\"max = \", ride_duration.max())\n",
    "print(\"mean = \",ride_duration.mean(),\"stdev = \",ride_duration.std())\n",
    "\n",
    "# how long was the min/max ride to the next integer minute\n",
    "min_ride = math.floor(ride_duration.min())\n",
    "print(\"min_ride = \", min_ride)\n",
    "max_ride = math.ceil(ride_duration.max())\n",
    "print(\"max_ride = \", max_ride)\n",
    "\n",
    "# histogram the ride time bin by the minute\n",
    "nBins = max_ride - min_ride\n",
    "cnts = ak.histogram(ride_duration, bins=nBins)\n",
    "\n",
    "# create bin edges because ak.histogram doesn't \n",
    "binEdges = np.linspace(ride_duration.min(), ride_duration.max(), nBins+1)\n",
    "print(binEdges)\n",
    "\n",
    "print(cnts.size,    \"cnts      = \", cnts)\n",
    "print(binEdges.size,\"bin edges = \", binEdges)\n",
    "\n",
    "# plot the histogram the ride time, bin by the minute\n",
    "plt.plot(binEdges[:-1],cnts.to_ndarray())\n",
    "plt.yscale('log')\n",
    "plt.xscale('linear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute somehting with trip distance in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ydf['trip_distance'].min(), ydf['trip_distance'].max())\n",
    "print(ydf['trip_distance'].mean(), ydf['trip_distance'].std())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(ydf['trip_distance'],bins=2000)\n",
    "#ax = plt.gca()\n",
    "#ax.set_xlim((ydf['trip_distance'].min(),ydf['trip_distance'].max()))\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute somehting with trip distance in Arkouda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi Zone Lookup Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the taxi-zone-lookup-table\n",
    "cvt = {'Borough':cvt_to_string, 'Zone':cvt_to_string, 'service_zone':cvt_to_string}\n",
    "tzlut = pd.read_csv(\"../Downloads/taxi+_zone_lookup.csv\",converters=cvt)\n",
    "# print out the tzlut which was read from file\n",
    "print(tzlut)\n",
    "\n",
    "# location id is 1-based, index is 0-based\n",
    "# fix it up to be aligned with index in data frame\n",
    "# which means add row zero\n",
    "top_row = pd.DataFrame({'LocationID': [0], 'Borough': ['N/A'], 'Zone': ['N/A'], 'service_zone': ['N/A']})\n",
    "tzlut = pd.concat([top_row, tzlut]).reset_index(drop = True)\n",
    "# print fixed up tzlut\n",
    "tzlut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the columns for all strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns for all strings\n",
    "print([\"{} is all str -> {}\".format(name, is_all_str(tzlut[name].values)) for name in tzlut.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataframe to dictionary of Arkouda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data frame with strings and int64 data\n",
    "aktzlut = ak_create_akdict_from_df(tzlut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what did we get on the server side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aktzlut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy pickup and dropoff location id\n",
    "- Compute something with Groupby/aggregate in Pandas and in Arkouda\n",
    "  - Groupby on pickup and dropoff location ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby puckup(PU) and dropoff(DO) location ids(LID)\n",
    "byLIDs = ak.GroupBy((akdict['PULocationID'], akdict['DOLocationID']))\n",
    "# print unique keys\n",
    "print('unique_keys (PU,DO): ', byLIDs.unique_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use groupby/aggregate on edge list to compute a condensed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a condensed graph of LID (PU,DO) pairs with different weights\n",
    "graphLID = {}\n",
    " # vertex names (integer)\n",
    "graphLID['V']    = aktzlut['LocationID']\n",
    "# unique edges\n",
    "graphLID['E']    = byLIDs.unique_keys\n",
    "# edge weight: count of each unique edge\n",
    "graphLID['W_CT'] = byLIDs.count()[1]\n",
    "# edge weight: mean trip distance per edge\n",
    "graphLID['W_TD'] = byLIDs.mean(akdict['trip_distance'])[1]\n",
    "# edge weight: mean ride duration per edge\n",
    "graphLID['W_RD'] = byLIDs.mean(ride_duration)[1]\n",
    "# edge weight: mean fare amount per edge\n",
    "graphLID['W_FA'] = byLIDs.mean(akdict['fare_amount'])[1]\n",
    "# print the graph\n",
    "print(\"graphLID = \", graphLID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - use join-with-dt\n",
    "  - other things\n",
    "- model number of taxis at a given time\n",
    "- model taxis as specific entities (Kalman filter?)\n",
    "  - use time and location ids\n",
    "  - probability of paths of taxis\n",
    "  - ...\n",
    "- other things?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disconnect from the server or shutdown the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disconnect or shutdown the server\n",
    "#ak.disconnect()\n",
    "#ak.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
